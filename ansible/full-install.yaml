# # Bootstrap machines
# - name: Bootstrap machines
#   hosts: all
#   vars:
#     do_bootstrap: false
#   tasks:
#     - name: Do boostrap
#       include_role: 
#         name: bootstrap
#       when: do_bootstrap

# # SSH and firewall configuration
# - name: configure storage node
#   hosts: storagenode
#   roles: storage-setup
# - name: configure manager node
#   hosts: managernode
#   roles: manager-setup
# - name: configure worker nodes
#   hosts: workers
#   roles: workers-setup
# - name: setup ssh and firewall
#   hosts: all
#   roles: common-setup

# # Install and initalize the Spark cluster
# - name: install hadoop, spark, and monitoring tools
#   hosts: all
#   roles: installations
# - name: create hdfs datanodes
#   hosts: workers:storagenode
#   roles: hdfs-datanodes
# - name: create namenode and spark master
#   hosts: managernode
#   roles: hadoop-spark-manager

# # perform the analysis
# - name: download protein data into hdfs
#   hosts: storagenode
#   tasks:
#     - name: Get data
#       include_role: 
#         name: download-data
#       vars:
#         ansible_remote_tmp: /data/tmp
#         datasets:
#           - dataset_name: ecoli
#             download_url: https://ftp.ebi.ac.uk/pub/databases/alphafold/latest/UP000000625_83333_ECOLI_v4.tar
#           - dataset_name: human
#             download_url: https://ftp.ebi.ac.uk/pub/databases/alphafold/latest/UP000005640_9606_HUMAN_v4.tar
- name: prepare merizo search on workers
  hosts: workers
  tasks:
    - name: get cath db
      include_role:
        name: merizo-dependencies
        tasks_from: get-cath-db.yaml
# - name: trigger spark job
#   hosts: managernode
#   roles: spark-job
# - name: results summaries 
#   hosts: storagenode
#   roles: run-summaries
  